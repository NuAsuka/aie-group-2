# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- датасет выбран: `S06-hw-dataset-02.csv`
- Размер: (18000, 39)
- Целевая переменная: `target`, где классы распределены так: 0 - 13273, 1 - 4727
- Признаки: только числовые (37 признаков)

## 2. Protocol

Разбиение: train/test 
- 25% test size
- random_state фиксированный (42)
- с сохранением частоты классов выборки y

При подборе гиперпараметров использовася CV на train с разбиением на 5 фолдов и оптимизировацией roc_auc.

Использовали следующие метрики для оценки моделей:
1. ROC-AUC как основная метрика для задачи с дисбалансом классов (74% и 26% доли классов)
2. F1-score как компромисс между precision и recall.
3. Accuracy как базовый ориентир, но с оговорками (дополняет другие метрики, не позволяет выносить объективнуб оценку из-за дизбаланса классов)

## 3. Models

Использовались в сравнении следующие модели
- DummyClassifier с стратегией stratified в качестве примитивного baseline. 
- LogisticRegression в качестве ещё одного baseline. Подбирались следующий гиперпараметр с помощью GridSearchCV:
    - обратная сила регуляризации (от 0.1 до 10)
- DecisionTreeClassifier с контролем сложности (подбором гиперпараметров) через GridSearchCV: 
    - `max_depth`
    - `min_samples_leaf` 
    - `ccp_alpha`
- RandomForestClassifier
    - `max_depth`
    - `min_samples_leaf` 
    - `max_features` (корень или 50%)
- HistGradientBoosting
    - `max_depth`
    - `max_leaf_nodes` 
    - `learning_rate`
- StackingClassifier (с CV-логикой для обучения метамодели)
    - никакие гиперпараметры не подбирались, что аргументируется тем, что базовые модели и так имеют неплохо подобранные гиперпараметры.
    - в качестве базовых моделей использовались: RandomForestClassifier, DecisionTreeClassifier, HistGradientBoosting.

## 4. Results

| №  | accuracy   | f1         | roc_auc    | model                  |
|----|------------|------------|------------|------------------------|
| 5  | 0.914444   | 0.828699   | 0.933555   | Stacking               |
| 4  | 0.905278   | 0.802548   | 0.931244   | HistGradientBoosting   |
| 3  | 0.891944   | 0.760025   | 0.928686   | RandomForest           |
| 2  | 0.836389   | 0.651685   | 0.841482   | DecisionTree           |
| 1  | 0.811944   | 0.560675   | 0.797692   | LogReg(scaled)         |
| 0  | 0.737500   | 0.000000   | 0.500000   | Dummy(most_frequent)   |

Победителем по ROC-AUC является Stacking. Данный результат является логичным, поскольку объединяет все решения всех трёх моделей, обученных для решения данной задачи (HistGradientBoosting, RandomForest, DecisionTree).

## 5. Analysis

Если поменять `random_state` хотя бы 5 прогонов для 1-2 моделей, то результаты моделей могут отличаться как в положительную, так и в отрицательную сторону. Объясняется это тем, что random_state влияет на разбиение/выборку(в начале обучения) данных и как следствие - обучение моделей. Для устойчивых моделей, например, HistGradientBoosting, Stacking колебания метрик будут незначительноым, а для менее стабильных моделей (DecisionTreeClassifier) возможны сильные колебания.

Модель Stacking ошибается в 111 случаях класса 0 и 199 случаях класса 1 FN. Несмотря на высокий ROC-AUC, модель не идеальна — она пропускает значительную часть положительных случаев (FN=199). Однако общая accuracy 91.4% показывает, что модель всё же эффективна в целом.

Наиболее важным признаком для модели Stacking является f16 (вклад 0.06 в ROC-AUC), за ним следуют f01, f19, f07 — они также сильно влияют на качество предсказаний. Остальные 11 признаков из топ-15 вносят меньший, но значимый вклад (0.01–0.02). Это говорит о том, что модель не полагается на один признак, а использует комбинацию нескольких, что повышает её устойчивость и обобщающую способность. Такой анализ помогает понять, какие признаки стоит сохранять при сокращении размерности или при интерпретации бизнес-логики модели.

## 6. Conclusion

1. Random_state - важный атрибут честного исследования, как и сохранение частоты данных при их делении.
2. Обычные деревья легко переобучаются при неограниченной глубине (становятся слишком не гибкие)
3. Для обеспечения хорошей гибкости деревьев можно использовать bagging и random forest, взамен на более долгое обучение и более устойчивый результат (к смене random_state)
4. Stacking хорошо себя показывает в качестве агрегации уже имеющихся сильных моделей. Важно обучать метамодель для staccking на основе OOF предсказаний.
5. В нелинейном датасете использовалие линейной регрессии в качестве baseline является неплохим кейсом.
